{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open Earth Foundation\n",
    "# Ocean Biodiversity Credit Data Framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the first notebook of a series of 5 notebooks that explains step by step how to calculate each modulating factor and assign credtis for the [Marine Biodiversity Credits methodology](https://zenodo.org/records/10182712) applied to the Cocos Marine Conservation Area of Costa Rica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Step 1: curate the IUCN data in the Eastern Tropical Pacific </h1>\n",
    "\n",
    "This notebook shows the first step in getting:\n",
    "- species distribution\n",
    "- species statuses\n",
    "\n",
    "and the pre-processing that goes along with it. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data sources\n",
    "\n",
    "The data needed for this project is available in the Ocean Program S3 Bucket\n",
    "\n",
    "**Species information**\n",
    "\n",
    "Unfortunately, at this time, this data needs to be manually downloaded by making a request to IUCN.\n",
    "\n",
    "From our S3 public bucket:\n",
    "https://ocean-program.s3.amazonaws.com/data/raw/IUCN_RedList_CentralPacific/\n",
    "\n",
    "**Geospatial information**\n",
    "\n",
    "The geospatial shapefiles were been downloaded from SNIT - CR. (link?)\n",
    "As our case study and example for these data pipelines, we use the Area de Conservación Marina Isla del Coco (ACMC)\n",
    "\n",
    "ACMC: https://ocean-program.s3.amazonaws.com/data/raw/MPAs/ACMC.geojson\n",
    "\n",
    "In point 2 you can find a way to access this data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Loading libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import boto3\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import concurrent.futures\n",
    "\n",
    "import fiona; #help(fiona.open)\n",
    "\n",
    "import seaborn as sns\n",
    "from shapely.geometry import Point\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Get the conservation area, i.e. the area of interest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cocos Island Coordinates**\n",
    "\n",
    "Cocos Island is located at 05°31′41″N; 87°03′40″W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cocos_lat = 5+31/60+41/3600\n",
    "Cocos_lon = -(87+3/60+40/3600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cocos = Point(Cocos_lon, Cocos_lat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Import entire ACMC**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ACMC = Coco Marine Conservation Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACMC = gpd.read_file('https://ocean-program.s3.amazonaws.com/data/raw/MPAs/ACMC.geojson')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the files and their Coordinate Reference Systems (CRS)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACMC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check the coordinate reference system:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACMC.crs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot to visually inspect the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "ax.set_aspect('equal')\n",
    "\n",
    "world.plot(ax=ax, color='white', edgecolor='black')\n",
    "\n",
    "ACMC.plot(ax=ax, alpha = 0.35, color = 'turquoise', label = 'ACMC')\n",
    "\n",
    "ax.scatter(Cocos.x, Cocos.y, c = 'r', label = 'Cocos Island')\n",
    "\n",
    "ax.set_xlim((-95, -75))\n",
    "ax.set_ylim((0, 12.5))\n",
    "ax.legend();\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nTotal Area, ACMC:\")\n",
    "print(\"{:0.2f}\".format(ACMC.area.item()) + \" sqdeg.\")\n",
    "print(\"{:,.2f}\".format(ACMC.to_crs(crs=31970).area.item()*10**(-6)) + \" sqkm in CRS 31970.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get the species data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data gathering for the distribution range\n",
    "\n",
    "This first step is the pre-processing to combine the ~7GB data downloaded from IUCN into a single shapefile that only covers the species within the ACMC. \n",
    "\n",
    "The outcome of this step has been saved in https://ocean-program.s3.amazonaws.com/data/processed/ACMC_IUCN_RedList/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all of the .shp files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize S3 client\n",
    "s3 = boto3.resource('s3')\n",
    "\n",
    "# Set the name of the bucket and the path to the shapefiles\n",
    "bucket = s3.Bucket('ocean-program')\n",
    "\n",
    "List = [obj.key for obj in bucket.objects.filter(Prefix='data/raw/IUCN_RedList_CentralPacific/')]\n",
    "\n",
    "fnames = [f's3://ocean-program/{s}' for s in List if '.shp' in str(s)]\n",
    "print(np.sort(fnames))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn the IUCN data into a geopandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read shapefiles\n",
    "def read_file(file, crs):\n",
    "    \n",
    "    gdf = gpd.read_file(file)\n",
    "    gdf = gdf.set_crs(epsg=crs, allow_override=True)\n",
    "    \n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start with the first data file to get column headers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fname = fnames[0]\n",
    "fname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = read_file(fname, 4326)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The dataframe has \" + str(len(gdf)) + \" rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = gpd.GeoDataFrame(columns = gdf.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Overlap with Marine Protected Area spatial boundaries </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case, we use as an example the Area de Conservation Marina Isla del Coco (ACMC)\n",
    "\n",
    "We now want to filter the dataframe to only keep rows that overlap with our area of interest, `ACMC`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: there are some rows in `gdf` that cause *issues* with a boolean filtering. Thus doing\n",
    "\n",
    "`df[df.overlaps(ACMC)]` or `df.loc[:][df.loc[:].overlaps(ACMC)]`\n",
    "\n",
    "gives the following error:\n",
    "```\n",
    "TopologicalError: The operation 'GEOSOverlaps_r' could not be performed. Likely cause is invalidity of the geometry <shapely.geometry.multipolygon.MultiPolygon object at 0x16b4b0880>\n",
    "```\n",
    "\n",
    "To avoid so, add `.buffer(0)`. It takes a longtime, however.\n",
    "\n",
    "\n",
    "We thus execute a for-loop over `gdf` to extract the rows that overlap with `ACMC`.\n",
    "\n",
    "See the python notebook / html file on data wrangling for this project. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------------------------------------------------------------------------------------------------------\n",
    "Run the next cell only for AMMB and later for PNIC for all the 0..4 files\n",
    "\n",
    "---------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_conservation = ACMC.geometry.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "area_of_conservation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timeit.timeit()\n",
    "print(\"We start with a df of length \" + str(len(gdf)))\n",
    "for idj in range(0, len(gdf)):\n",
    "    try:\n",
    "        if gdf.loc[idj].geometry.overlaps(area_of_conservation):\n",
    "            df1 = df1.append(gdf.loc[idj])\n",
    "    except:\n",
    "        try:\n",
    "            if gdf.loc[idj].geometry.buffer(0).overlaps(area_of_conservation):\n",
    "                df1 = df1.append(gdf.loc[idj])\n",
    "        except:\n",
    "            print(\"Issue at row \" + str(idj))\n",
    "            pass\n",
    "end = timeit.timeit()    \n",
    "print(\"We end with a df of length \" + str(len(df1)) + \" and it took:\")\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we append the rest of the files in fnames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in fnames[1:]:\n",
    "    gdf = read_file(fname, 4326)\n",
    "    print(\"The dataframe has \" + str(len(gdf)) + \" rows.\")\n",
    "    print(gdf.crs)\n",
    "    start = timeit.timeit()\n",
    "    \n",
    "    for idj in range(0, len(gdf)):\n",
    "        try:\n",
    "            if gdf.loc[idj].geometry.overlaps(area_of_conservation):\n",
    "                df1 = df1.append(gdf.loc[idj])\n",
    "        except:\n",
    "            try:\n",
    "                if gdf.loc[idj].geometry.buffer(0).overlaps(area_of_conservation):\n",
    "                    df1 = df1.append(gdf.loc[idj])\n",
    "            except:\n",
    "                print(\"Issue at row \" + str(idj))\n",
    "                pass\n",
    "    end = timeit.timeit()    \n",
    "    print(\"We end with a df of length \" + str(len(df1)) + \" and it took:\")\n",
    "    print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.to_file('gdf_species_in_ACMC.shp') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`gdf_species_in_ACMC.shp` is the saved output. It is also on the Drive. It can be retrieved doing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = gpd.read_file('s3://ocean-program/data/processed/ACMC_IUCN_RedList/gdf_species_in_ACMC.shp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df1.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"There are \" + str(len(df1)) + \" unique species in this dataset.\")\n",
    "print(\"The dates span \" + str(df1.YEAR.min()) + \" to \" + str(df1.YEAR.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.2 Get the conservation status </h2>\n",
    "\n",
    "This was also manually downloaded following a manual request to UICN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stat = pd.read_csv('s3://ocean-program/data/raw/IUCN_RedList_CentralPacific/IUCN status - redlist_species_data_a5560fc7-ec95-45c9-8c1f-364584e4173d/assessments.csv')\n",
    "stat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 2.3 Append conservation status to list of species & distribution </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make copies to be safe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df1.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan['BINOMIAL'].isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"With nan's we have \" + str(len(df)) + \" rows.\")\n",
    "print(\"Without nan's we have \" + str(len(df_nonan[~df_nonan['BINOMIAL'].isnull()])) + \" rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan = df_nonan[~df_nonan['BINOMIAL'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_nonan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan[\"redlistCategory\"] = \"\"\n",
    "df_nonan[\"scientificName\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scientificName = []\n",
    "redlistCategory = []\n",
    "for iter, row in df_nonan.iterrows():\n",
    "    try:\n",
    "        redlistCategory.append(stat[stat.scientificName==row.BINOMIAL].redlistCategory.item())\n",
    "        scientificName.append(row.BINOMIAL)\n",
    "    except:\n",
    "        try:\n",
    "            redlistCategory.append(stat[stat.scientificName==row.BINOMIAL].redlistCategory)\n",
    "            scientificName.append(row.BINOMIAL)\n",
    "        except:\n",
    "            redlistCategory.append(\"No category found\")\n",
    "            scientificName.append(row.BINOMIAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan[\"redlistCategory\"] = redlistCategory\n",
    "df_nonan[\"scientificName\"] = scientificName\n",
    "df_nonan.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We just check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "(df_nonan.scientificName==df_nonan.BINOMIAL).unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have the following conservation statuses:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan.redlistCategory.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for status in df_nonan.redlistCategory.unique():\n",
    "    print(\"There are \" + str(len(df_nonan[df_nonan.redlistCategory==status])) + \\\n",
    "          \" species with the status \" + status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The species with the status Critically Endangered are :\")\n",
    "print(df_nonan[df_nonan.redlistCategory=='Critically Endangered'].BINOMIAL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- *Carcharhinus longimanus* is Oceanic whitetip shark\n",
    "- *Eretmochelys imbricata* is Hawksbill sea turtle\n",
    "- *Pristis pristis* is Largetooth sawfish"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alternative approach to merging the DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename column\n",
    "stat.rename(columns = {'internalTaxonId':'ID_NO'}, inplace=True)\n",
    "stat.columns, df_nonan.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert ID_NO from string to int\n",
    "df_nonan[['ID_NO']] = df_nonan[['ID_NO']].apply(pd.to_numeric)\n",
    "df_nonan.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACMC_IUCN_df = df_nonan.merge(stat, on=['ID_NO'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACMC_IUCN_df.scientificName_x.equals(ACMC_IUCN_df.scientificName_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Drop unused columns\n",
    "drop_cols = ['redlistCriteria', 'yearPublished', 'assessmentDate', 'criteriaVersion',\n",
    "       'language', 'rationale', 'habitat', 'threats', 'population','populationTrend', 'range', 'useTrade', 'systems',\n",
    "       'conservationActions', 'realm', 'yearLastSeen', 'possiblyExtinct', 'possiblyExtinctInTheWild', 'scopes','scientificName_y','redlistCategory_y',\n",
    "        'assessmentId']\n",
    "ACMC_IUCN_df.drop(columns=drop_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now remove all geometries that are outside the ACMC -> clip does the job\n",
    "#ACMC_IUCN_df1 = gpd.clip(ACMC_IUCN_df.set_crs(epsg=4326, allow_override=True), ACMC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACMC_IUCN_df.columns, len(ACMC_IUCN_df), ACMC_IUCN_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACMC_IUCN_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ACMC_IUCN_df1.drop('index_left', inplace=True, axis=1)\n",
    "ACMC_IUCN_df1 = ACMC_IUCN_df.reset_index(drop=True).sort_values(['ID_NO'])\n",
    "ACMC_IUCN_df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> 3. Saving output </h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent! We save the final result as `gdf_ACMC_IUCN_range_status_filtered.shp` under `ACMCC_IUCN_data`. It is also on the Drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nonan.to_file('gdf_ACMC_IUCN_range_status_filtered.shp') "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
